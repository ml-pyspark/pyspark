{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Spark specific Library\n",
    "## importing the library needed for spark to work and run in our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import User defined Library\n",
    "### 1. EncodeLib :contains different packages for label encoding as well as One hot encoding and vectorizing \n",
    "### 2. CleanLib : contains DataCleanLib which can be invoked to clean data passed\n",
    "### 3. S3Serializer : Package for remote data access\n",
    "### 4. MultiLabel : Package contains MultiLabel classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encode_Lib.EncodeLib import LabelEncode,OHEncode,VectorChange\n",
    "from Data_Cleaning_Lib.CleanLib import  DataCleaningLib\n",
    "from S3serializer_Lib.S3Serializer import S3Bucket\n",
    "import Encode_Lib.EncodeLib as eimEncode\n",
    "import  Data_Cleaning_Lib.CleanLib as eimclean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating spark Instance\n",
    "## creating a session 'product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('product').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to remote Cluster using our library S3Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host  18.212.194.194\n",
      "Connected\n"
     ]
    }
   ],
   "source": [
    "s3=S3Bucket()\n",
    "s3.connect(host = \"18.212.194.194\", username = \"centos\", key = './InternalPOC_Digital.pem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting complete folder from remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Getting File--> part-00000-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00001-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00002-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00003-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00004-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00005-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00006-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00007-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00008-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00009-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00010-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00011-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00012-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00013-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00014-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00015-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00016-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> part-00017-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet\n",
      "Getting File--> _SUCCESS\n",
      "['part-00000-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00001-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00002-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00003-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00004-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00005-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00006-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00007-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00008-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00009-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00010-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00011-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00012-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00013-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00014-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00015-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00016-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', 'part-00017-a3a6f736-9b2b-4010-a7bd-7509e347862c-c000.snappy.parquet', '_SUCCESS']\n"
     ]
    }
   ],
   "source": [
    "s3.get_dir_remote('this.parquet','this.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the parquet file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.parquet('./this.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.limit(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the date and time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(*['fecha_dato','ult_fec_cli_1t','fecha_alta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the DataCleaningLib to clean the data\n",
    "### 1. Removing Null values\n",
    "### 2. Removing string provided \"NA\" /'NAN' values\n",
    "### 3. Imputing categorical data with the max count\n",
    "### 4. Imputing numerical columns with mean values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Data Cleaning and Preprocessing\n",
      "processing--> ncodpers\n",
      "processing--> ind_empleado\n",
      "processing--> pais_residencia\n",
      "processing--> sexo\n",
      "processing--> age\n",
      "processing--> ind_nuevo\n",
      "processing--> antiguedad\n",
      "processing--> indrel\n",
      "processing--> indrel_1mes\n",
      "processing--> tiprel_1mes\n",
      "processing--> indresi\n",
      "processing--> indext\n",
      "processing--> conyuemp\n",
      "processing--> canal_entrada\n",
      "processing--> indfall\n",
      "processing--> tipodom\n",
      "processing--> cod_prov\n",
      "processing--> nomprov\n",
      "processing--> ind_actividad_cliente\n",
      "processing--> renta\n",
      "processing--> segmento\n",
      "processing--> ind_ahor_fin_ult1\n",
      "processing--> ind_aval_fin_ult1\n",
      "processing--> ind_cco_fin_ult1\n",
      "processing--> ind_cder_fin_ult1\n",
      "processing--> ind_cno_fin_ult1\n",
      "processing--> ind_ctju_fin_ult1\n",
      "processing--> ind_ctma_fin_ult1\n",
      "processing--> ind_ctop_fin_ult1\n",
      "processing--> ind_ctpp_fin_ult1\n",
      "processing--> ind_deco_fin_ult1\n",
      "processing--> ind_deme_fin_ult1\n",
      "processing--> ind_dela_fin_ult1\n",
      "processing--> ind_ecue_fin_ult1\n",
      "processing--> ind_fond_fin_ult1\n",
      "processing--> ind_hip_fin_ult1\n",
      "processing--> ind_plan_fin_ult1\n",
      "processing--> ind_pres_fin_ult1\n",
      "processing--> ind_reca_fin_ult1\n",
      "processing--> ind_tjcr_fin_ult1\n",
      "processing--> ind_valo_fin_ult1\n",
      "processing--> ind_viv_fin_ult1\n",
      "processing--> ind_nomina_ult1\n",
      "processing--> ind_nom_pens_ult1\n",
      "processing--> ind_recibo_ult1\n",
      "!-----DONE------!\n",
      "2.IMPUTING CATEGORICAL VALUES\n",
      "Imputing--> antiguedad\n",
      "Imputing--> nomprov\n",
      "Imputing--> indext\n",
      "Imputing--> tiprel_1mes\n",
      "Imputing--> ind_nuevo\n",
      "Imputing--> ind_nomina_ult1\n",
      "Imputing--> ind_nom_pens_ult1\n",
      "Imputing--> indrel_1mes\n",
      "Imputing--> age\n",
      "Imputing--> ind_empleado\n",
      "Imputing--> ind_actividad_cliente\n",
      "Imputing--> indresi\n",
      "Imputing--> sexo\n",
      "Imputing--> canal_entrada\n",
      "Imputing--> pais_residencia\n",
      "Imputing--> indrel\n",
      "Imputing--> cod_prov\n",
      "Imputing--> indfall\n",
      "Imputing--> tipodom\n",
      "Imputing--> segmento\n",
      "3.IMPUTING NUMERICAL VALUES\n",
      "Final number of columns after pre-processing 44\n"
     ]
    }
   ],
   "source": [
    "data_cleaning=DataCleaningLib()\n",
    "data=data_cleaning.cleaning(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting data format from string to integer\n",
    "#### [Auto casting  can be a feature of our library in upcoming versions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.withColumn('age',data['age'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.withColumn('ind_nom_pens_ult1',data['ind_nom_pens_ult1'].cast('int'))\n",
    "data=data.withColumn('ind_nomina_ult1',data['ind_nomina_ult1'].cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cleaned file in parquet format(dividing the file into multiple chunks)\n",
    "#### why?\n",
    "#### 1. Reduces the size of the data (2gb data is converted to 100 mb further divided into 5 chunks of 20mb)\n",
    "#### 2. Fetching huge data from remote at once can be memory and time consuming\n",
    "#### 3. When getting/saving huge data from/to remote there can be errors thus crashing the file [thus fetching in chunks help in avoiding fatal errors / whole file to be corrupted] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.write.parquet('clean_data_V1.01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the cleaned data to remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Saving File--> .part-00000-7a8d8518-0142-4a17-8c96-7cece3cabeae-c000.snappy.parquet.crc\n",
      "Saving File--> ._SUCCESS.crc\n",
      "Saving File--> _SUCCESS\n",
      "Saving File--> part-00000-7a8d8518-0142-4a17-8c96-7cece3cabeae-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "s3.save_dir_remote('clean_data_V1.01.parquet','clean_data_V1.01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the product columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns=[col for col in data.columns if col.startswith('ind_') and col.endswith('ult1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns.append('ncodpers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding the values\n",
    "## why implement our own?\n",
    "#### 1. StringIndexer (spark's native label encoder) needs user to pass in what are the columns which are needed to be encoded\n",
    "#### 2. LabelEncoder automates the whole process for us \n",
    "#### 3. The only needed input is the Target/label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncode(outputCols=label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antiguedad\n",
      "nomprov\n",
      "indext\n",
      "tiprel_1mes\n",
      "ind_nuevo\n",
      "indrel_1mes\n",
      "ind_empleado\n",
      "ind_actividad_cliente\n",
      "indresi\n",
      "sexo\n",
      "canal_entrada\n",
      "pais_residencia\n",
      "indrel\n",
      "cod_prov\n",
      "indfall\n",
      "tipodom\n",
      "segmento\n"
     ]
    }
   ],
   "source": [
    "data = le.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding:\n",
    "### Our implementaion of OHE as LabelEncoders is automatic. it One Hot encodes the Label encoded data as well as determines if the above transformation is necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OHEncode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.drop('index_tipodom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=ohe.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Assembly :\n",
    "### converting all the features into a single Vector space named 'features' which will in turn be used for our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = VectorChange(outputCols=label_columns)\n",
    "tem = vec.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ncodpers: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- ind_nomina_ult1: integer (nullable = true)\n",
      " |-- ind_nom_pens_ult1: integer (nullable = true)\n",
      " |-- ind_recibo_ult1: integer (nullable = true)\n",
      " |-- imputed_renta: double (nullable = true)\n",
      " |-- index_indext: double (nullable = false)\n",
      " |-- index_ind_nuevo: double (nullable = false)\n",
      " |-- index_ind_actividad_cliente: double (nullable = false)\n",
      " |-- index_indresi: double (nullable = false)\n",
      " |-- index_sexo: double (nullable = false)\n",
      " |-- index_indrel: double (nullable = false)\n",
      " |-- index_indfall: double (nullable = false)\n",
      " |-- index_tipodom: double (nullable = false)\n",
      " |-- ohe_index_antiguedad: vector (nullable = true)\n",
      " |-- ohe_index_nomprov: vector (nullable = true)\n",
      " |-- ohe_index_tiprel_1mes: vector (nullable = true)\n",
      " |-- ohe_index_indrel_1mes: vector (nullable = true)\n",
      " |-- ohe_index_ind_empleado: vector (nullable = true)\n",
      " |-- ohe_index_canal_entrada: vector (nullable = true)\n",
      " |-- ohe_index_pais_residencia: vector (nullable = true)\n",
      " |-- ohe_index_cod_prov: vector (nullable = true)\n",
      " |-- ohe_index_segmento: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tem.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the final clean and Vectorizied data to the remote Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tem.write.parquet('product_rec_V1.01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Saving File--> ._SUCCESS.crc\n",
      "Saving File--> part-00000-3298b50d-6067-4afe-a3ee-c0f3a1fd69d1-c000.snappy.parquet\n",
      "Saving File--> .part-00000-3298b50d-6067-4afe-a3ee-c0f3a1fd69d1-c000.snappy.parquet.crc\n",
      "Saving File--> _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "s3.save_dir_remote('product_rec_V1.01.parquet','product_rec_V1.01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving the data into train test Splits for model training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=tem.randomSplit([0.5,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EimCC-MultiLabel contains classifiers for MultiLabel classification\n",
    "## PySpark has no native library build for such kind of problems\n",
    "## Features:\n",
    "## 1. Can perform Multi-Label Classification\n",
    "##                  2. Gives a recommendation of products for each customer \n",
    "##                  3. Gives the current list of products for each customer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EimCC.MultiLabel import BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=BinaryRelevance(featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.fit(train,label_columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functionality of Saving Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.save('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.load('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=b.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': ['ind_cno_fin_ult1',\n",
       "  'ind_ctop_fin_ult1',\n",
       "  'ind_ctpp_fin_ult1',\n",
       "  'ind_dela_fin_ult1',\n",
       "  'ind_hip_fin_ult1',\n",
       "  'ind_nom_pens_ult1',\n",
       "  'ind_recibo_ult1'],\n",
       " 'recommendation': ['ind_cco_fin_ult1']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.find_recommendation(user=15906.0,id_column='ncodpers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
